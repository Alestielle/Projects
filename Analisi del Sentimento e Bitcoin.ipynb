{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e1e5d50f-7765-466a-bac0-9dc95f9e0a4e",
     "showTitle": false,
     "title": ""
    },
    "id": "sABH0oPvJUpJ"
   },
   "source": [
    "# Analisi del consenso sul Bitcoin\n",
    "\n",
    "Sei stato reclutato da un'azienda di ricerche di mercato per stimare il consenso delle persone verso il Bitcoin. Un team di data engineer ha estratto diversi milioni di tweet che parlano di Bitcoin, il tuo compito è quello di eseguire un'analisi del sentiment e creare un grafico che mostri come questo è variato giorno per giorno. Utilizza anche i dati per rispondere a domande interessanti, come:\n",
    "- i tweet negativi hanno avuto più likes rispetto a quelli positivi?\n",
    "- i tweet negativi hanno avuto più interazioni (risposte) rispetto a quelli positivi?\n",
    "\n",
    "#### BONUS\n",
    "Verifica se la variazione del sentiment è associata ad una variazione del valore del Bitcoin, per svolgere questa task devi reperire in autonomia lo storico di BTC USD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0549c216-1343-4883-b676-cd3c6ec7a2ca",
     "showTitle": false,
     "title": ""
    },
    "id": "TQVBmyxsp_bB"
   },
   "source": [
    "Lo svolgimento di questo progetto comincia con l'installazione delle librerie che utilizzeremo nel codice. La prima parte di codice compilato consiste nel scaricare da link il dataset che utilizzeremo, effettuare una pulizia dell'head delle colonne e dello stesso dataset, eliminando dati che non servono alle analisi quali ad esempio virgole, punti, simboli ed emoji. Successivamente viene creato il datafrake spark, in quanto nella compilazione di questo codice sarà preferito ove possibile utilizzare Apache spark, e successivamente creare una Table che verrà caricata nell'ambiente Databricks, il cui nome è bitcoin_tweet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "456ec5c2-9d8c-44e8-9755-3a1ea3789105",
     "showTitle": false,
     "title": ""
    },
    "id": "myjkYe4ppG0K"
   },
   "outputs": [],
   "source": [
    "pip install py spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "06fb3eaa-4343-4514-8755-892d494b2014",
     "showTitle": false,
     "title": ""
    },
    "id": "swjU5d-4pHXj"
   },
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2ea0bc4-f0ab-4bf8-acd6-e15a73559996",
     "showTitle": false,
     "title": ""
    },
    "id": "D0yzOkuMpHiS"
   },
   "outputs": [],
   "source": [
    "pip install TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4900eee1-3d59-4e11-bc20-2767bf861673",
     "showTitle": false,
     "title": ""
    },
    "id": "shx4G3gSpNsq"
   },
   "outputs": [],
   "source": [
    "pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cbf4af81-bed4-446f-b32c-84c7cc6810e8",
     "showTitle": false,
     "title": ""
    },
    "id": "oeIE_D3JpWlx"
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "import re\n",
    "import emoji\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "!wget https://proai-datasets.s3.eu-west-3.amazonaws.com/bitcoin_tweets.csv\n",
    "\n",
    "import pandas as pd\n",
    "dataset = pd.read_csv('bitcoin_tweets.csv', delimiter=\";\", low_memory=False)\n",
    "\n",
    "# Pulizia dei nomi delle colonne\n",
    "new_column_names = [col.replace(' ', '_').replace(',', '_').replace(';', '_').replace('{', '_').replace('}', '_')\n",
    "                    .replace('(', '_').replace(')', '_').replace('\\n', '_').replace('\\t', '_').replace('=', '_')\n",
    "                    for col in dataset.columns]\n",
    "dataset.columns = new_column_names\n",
    "\n",
    "def remove_emoji(text):\n",
    "    if isinstance(text, str):\n",
    "        emoji_pattern = re.compile(\"[\"\n",
    "                                   u\"\\U0001F600-\\U0001F64F\"  # emoticon\n",
    "                                   u\"\\U0001F300-\\U0001F5FF\"  # simboli & pittogrammi\n",
    "                                   u\"\\U0001F680-\\U0001F6FF\"  # trasporti & simboli mappe\n",
    "                                   u\"\\U0001F1E0-\\U0001F1FF\"  # bandiere (iOS)\n",
    "                                   u\"\\U00002702-\\U000027B0\"\n",
    "                                   u\"\\U000024C2-\\U0001F251\"\n",
    "                                   \"]+\", flags=re.UNICODE)\n",
    "        return emoji_pattern.sub(r'', text)\n",
    "    else:\n",
    "        return text  # Restituisce l'input se non è una stringa\n",
    "\n",
    "\n",
    "# Funzione per pulire il testo\n",
    "def clean_text(text):\n",
    "    if text is not None:\n",
    "        text = remove_emoji(text)\n",
    "        text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "# Crea il DataFrame Spark\n",
    "spark_df = spark.createDataFrame(dataset)\n",
    "\n",
    "# Applica la pulizia del testo alla colonna \"Text\"\n",
    "clean_text_udf = F.udf(clean_text)\n",
    "spark_df = spark_df.withColumn(\"Text\", clean_text_udf(spark_df[\"Text\"]))\n",
    "\n",
    "# Salva il DataFrame pulito come tabella\n",
    "spark_df.write.saveAsTable(\"bitcoin_tweets\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f72c3520-5a92-4dad-80d3-51c42864f836",
     "showTitle": false,
     "title": ""
    },
    "id": "fI2CvuCTr4gR"
   },
   "source": [
    "Creiamo una funzione Python analyze_sentiment_udf che prende un testo come input, utilizza TextBlob per analizzare il sentimento di quel testo e restituisce una stringa rappresentante il sentiment (Positivo, Negativo o Neutro), e utilizziamo il metodo udf per registrare la funzione analyze_sentiment_udf, infine verrà aggiunta la colonna Sentiment al Dataframe che contiene i 3 tipi di sentimento elencati prima, e un ulteriore modifica al dataframe eliminando valori nulli nel sentiment, nel text e cambiando il nome della colonna Timestamp ,che contiene le date, che chiameremo Data e perfezioneremo il contenuto rimuovendo l'orario, dato poco utile all'analisi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "edf788fe-9c2b-4638-88a2-0db5111c40bc",
     "showTitle": false,
     "title": ""
    },
    "id": "NmTOhc8npfNK"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "# Definiamo una funzione per l'analisi del sentiment utilizzando TextBlob\n",
    "def analyze_sentiment_udf(text):\n",
    "    if text is not None and isinstance(text, str):\n",
    "        analysis = TextBlob(text)\n",
    "        sentiment_score = analysis.sentiment.polarity\n",
    "        if sentiment_score > 0:\n",
    "            return \"Positive\"\n",
    "        elif sentiment_score < 0:\n",
    "            return \"Negative\"\n",
    "        else:\n",
    "            return \"Neutral\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Creiamo una User Defined Function (UDF) per l'analisi del sentiment\n",
    "analyze_sentiment = udf(analyze_sentiment_udf, StringType())\n",
    "\n",
    "# Aggiungere la colonna 'sentiment' al DataFrame\n",
    "spark_df = spark_df.withColumn('sentiment', analyze_sentiment(spark_df['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c2cac1f8-bbc6-451f-b80e-132418e663c6",
     "showTitle": false,
     "title": ""
    },
    "id": "23DxH0eZtWgy"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "# Sostituisce i valori nulli nella colonna \"sentiment\" con una stringa vuota\n",
    "spark_df = spark_df.withColumn(\"sentiment\", when(spark_df[\"sentiment\"].isNull(), \"\").otherwise(spark_df[\"sentiment\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f24bd036-fd8a-40c4-9064-bac7de308584",
     "showTitle": false,
     "title": ""
    },
    "id": "Kgx944MDtXNp"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "# Filtra i record con valori nulli nella colonna \"text\"\n",
    "filtered_df = spark_df.filter(col(\"text\").isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4bacc3e5-ed1b-46c3-9cb9-b384f4912573",
     "showTitle": false,
     "title": ""
    },
    "id": "4mevsZaytl2J"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import date_format\n",
    "\n",
    "# Aggiunge una nuova colonna \"Date\" con solo la data, senza l'orario\n",
    "filtered_df = filtered_df.withColumn(\"Date\", date_format(col(\"timestamp\"), \"yyyy-MM-dd\"))\n",
    "\n",
    "# Rimuove la colonna \"timestamp\" se non è più necessaria\n",
    "filtered_df = filtered_df.drop(\"timestamp\")\n",
    "\n",
    "filtered_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d92fad1d-355e-462e-ab88-4901c50c58ce",
     "showTitle": false,
     "title": ""
    },
    "id": "NMyUPBaE75Tx"
   },
   "source": [
    "Ora ci interessiamo a eseguire un'analisi del sentiment e creare un grafico che mostri come questo è variato giorno per giorno, Per rendere il grafico visualizzabile ci concentreremo su un lasso di tempo di 15 giorni del mese di  Gennaio del 2017 , dal grafico risultante osserviamo, un sentimento Neutral che varia molto, ma la più utilizzata dagli utenti basandoci sui numeri. Una costanza nei tweet negativi, il cui numerio è comunque contenuto, e una linea positiva che varia abbastanza in base alle giornate, superando in ogni caso i numeri dei tweet negativi ma mantenendo una soglia lontana dai numeri del Neutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "28ea23a2-9cb6-475e-88ff-342e8f79fdb4",
     "showTitle": false,
     "title": ""
    },
    "id": "sE7_C7umtnBJ"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Filtra i dati relativi ai primi 15 giorni di gennaio 2017\n",
    "start_date = \"2017-01-01\"\n",
    "end_date = \"2017-01-15\"\n",
    "filtered_df_jan_2017 = filtered_df.filter((F.col(\"Date\") >= start_date) & (F.col(\"Date\") <= end_date))\n",
    "\n",
    "# Raggruppa per giorno e sentimento e conta il numero di tweet per ogni combinazione di giorno e sentimento\n",
    "sentiment_counts_jan_2017 = filtered_df_jan_2017.groupBy(\"Date\", \"sentiment\").count()\n",
    "\n",
    "# Calcolo della somma dei tweet positivi, negativi e neutri per ogni giorno\n",
    "positive_counts = sentiment_counts_jan_2017.filter(sentiment_counts_jan_2017.sentiment == \"Positive\") \\\n",
    "                                           .withColumnRenamed(\"count\", \"Positive_Count\")\n",
    "negative_counts = sentiment_counts_jan_2017.filter(sentiment_counts_jan_2017.sentiment == \"Negative\") \\\n",
    "                                           .withColumnRenamed(\"count\", \"Negative_Count\")\n",
    "neutral_counts = sentiment_counts_jan_2017.filter(sentiment_counts_jan_2017.sentiment == \"Neutral\") \\\n",
    "                                           .withColumnRenamed(\"count\", \"Neutral_Count\")\n",
    "\n",
    "# Unione conteggi positivi, negativi e neutri\n",
    "merged_counts = positive_counts.join(negative_counts, \"Date\", \"outer\") \\\n",
    "                               .join(neutral_counts, \"Date\", \"outer\").na.fill(0)\n",
    "\n",
    "# Calcolo della variazione del sentiment per ogni giorno\n",
    "merged_counts = merged_counts.withColumn(\"Sentiment_Variation\", \\\n",
    "                                         (F.col(\"Positive_Count\") - F.col(\"Negative_Count\")) / \\\n",
    "                                         (F.col(\"Positive_Count\") + F.col(\"Negative_Count\") + F.coalesce(F.col(\"Neutral_Count\"), F.lit(0))))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ee8e102-2cb3-4106-ada2-a8d1b3f7196f",
     "showTitle": false,
     "title": ""
    },
    "id": "zbqUmKUD2Ibx"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "merged_counts_pd = merged_counts.toPandas()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(merged_counts_pd[\"Date\"], merged_counts_pd[\"Positive_Count\"], marker='o', linestyle='-', label=\"Positive\", color='blue')\n",
    "\n",
    "plt.plot(merged_counts_pd[\"Date\"], merged_counts_pd[\"Negative_Count\"], marker='o', linestyle='-', label=\"Negative\", color='red')\n",
    "\n",
    "plt.plot(merged_counts_pd[\"Date\"], merged_counts_pd[\"Neutral_Count\"], marker='o', linestyle='-', label=\"Neutral\", color='green')\n",
    "\n",
    "plt.xticks(fontsize=8, rotation=45, color='gray')\n",
    "\n",
    "plt.title(\"Tweets per Day in January 2017 by Sentiment\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Tweet Count\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "29c759b0-3e63-42c7-b71b-05e98b8492b6",
     "showTitle": false,
     "title": ""
    },
    "id": "Pq6yHdXONaN9"
   },
   "source": [
    "Successivamente facciamo un'indagine per vedere se i tweet negativi hanno avuto più likes rispetto a quelli positivi, osserveremo dalla table ottenuta che vi è una differenza sostanziale in quanto tweet positivi sono molti di più dei tweet negativi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2df6060-908f-4d4d-accb-ef4b0fdf942f",
     "showTitle": false,
     "title": ""
    },
    "id": "Xv3CjkL7H9NZ"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sum\n",
    "\n",
    "# Selezione delle colonne \"sentiment\" e \"likes\" dal DataFrame filtrato\n",
    "sent_likes = filtered_df.select(\"sentiment\", \"likes\")\n",
    "\n",
    "# Raggruppamento per \"sentiment\" e calcolo della somma dei \"likes\"\n",
    "sum_likes = sent_likes.groupBy(\"sentiment\").agg(sum(\"likes\").alias(\"sum_likes\"))\n",
    "\n",
    "# Visualizzazione del DataFrame risultante\n",
    "display(sum_likes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e022d90a-ba10-48c2-a0aa-1540fb880c0a",
     "showTitle": false,
     "title": ""
    },
    "id": "S3tdY7v-xEXO"
   },
   "source": [
    "Altra indagine è quella di occuparci di vedere se tweet negativi hanno avuto più interazioni (risposte) rispetto a quelli positivi, approccio simile ai likes, evidenzia una differenza evidente fra le varie tipologie di sentimento,con una prevalenza di Neutral, in ogni caso le \"replies\" Positive superano quelle Negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba06be11-c015-44e4-87c3-98d0558e03fe",
     "showTitle": false,
     "title": ""
    },
    "id": "V0bcYYofxDu-"
   },
   "outputs": [],
   "source": [
    "# Selezione delle colonne \"sentiment\" e \"replies\" dal DataFrame filtrato\n",
    "sent_replies = filtered_df.select(\"sentiment\", \"replies\")\n",
    "\n",
    "# Raggruppamento per \"sentiment\" e calcolo della somma delle \"replies\"\n",
    "sum_replies = sent_replies.groupBy(\"sentiment\").agg(sum(\"replies\").alias(\"sum_replies\"))\n",
    "\n",
    "# Visualizzazione del DataFrame risultante\n",
    "display(sum_replies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d7b9c248-99bf-4a8e-b10b-f7bba02c9f47",
     "showTitle": false,
     "title": ""
    },
    "id": "2E6CLLumx_nv"
   },
   "source": [
    "Infine ci occupiamo di verificare se la variazione del sentiment è associata ad una variazione del valore del Bitcoin, e lo illustriamo in un grafico. Per prima cosa creiamo un dataframes spark dal csv fonte, facciamo una breve pulizia rinominando le colonne e togliendo il punto, la percentuale e la lettera K da Volume, uniamo infine il dataframe filterd_df a bitcoin_df; a questo punto calcoliamo la media giornaliera per ogni sentiment tenendo conto che come arco temporale utilizzeremo solo Gennaio 2017 per rendere il grafico leggibile. Visualizzeremo che il sentimento positivo è associato a una variazione positiva del Bitcoin, mentre il sentimento negativo è associato a una variazione negativa del Bitcoin.Tuttavia, ci sono alcune eccezioni a questa regola. Ad esempio, il 17 gennaio il sentimento medio era negativo, ma la variazione del Bitcoin era positiva. Questo può essere dovuto ad altri fattori, come le notizie o gli eventi che hanno avuto luogo quel giorno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3918791-8273-4887-a0cb-760cfd115096",
     "showTitle": false,
     "title": ""
    },
    "id": "DbabdF9ox_YZ"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import lag, col, regexp_replace, to_date\n",
    "\n",
    "bitcoin_df = spark.table(\"default.bitcoin_dati_storici_csv\")\n",
    "\n",
    "bitcoin_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f0fee88-e12a-4a6f-8ea9-84af95742ffd",
     "showTitle": false,
     "title": ""
    },
    "id": "JbivFQ1V2PrG"
   },
   "outputs": [],
   "source": [
    "\n",
    "bitcoin_df = bitcoin_df.withColumn(\"Data\", to_date(\"Data\", \"dd.MM.yyyy\"))\n",
    "\n",
    "bitcoin_df = bitcoin_df.withColumnRenamed(\"Vol.\", \"Volume\").withColumnRenamed(\"Var. %\", \"Variazione\")\n",
    "\n",
    "bitcoin_df = bitcoin_df.withColumn(\"Volume\", regexp_replace(bitcoin_df[\"Volume\"], \"K\", \"\"))\n",
    "\n",
    "bitcoin_df = bitcoin_df.withColumn(\"Variazione\", regexp_replace(bitcoin_df[\"Variazione\"], \"%\", \"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7dc9e003-b752-4b97-8645-df7d7742da06",
     "showTitle": false,
     "title": ""
    },
    "id": "_nPcgz5f2ite"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Rinominiamo la colonna \"Data\" in \"Date\" nel DataFrame bitcoin_df\n",
    "bitcoin_df = bitcoin_df.withColumnRenamed(\"Data\", \"Date\")\n",
    "\n",
    "# Unione DataFrame utilizzando la colonna \"Date\"\n",
    "joined_df = bitcoin_df.join(filtered_df, bitcoin_df[\"Date\"] == filtered_df[\"Date\"], \"inner\")\n",
    "\n",
    "# Eliminiamo una delle colonne \"Date\" dal DataFrame unito\n",
    "joined_df = joined_df.drop(filtered_df[\"Date\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e1210fd-4efc-4d02-90c5-de326a9c303e",
     "showTitle": false,
     "title": ""
    },
    "id": "fmxqZlUi2xK2"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year, month, col, when\n",
    "\n",
    "# Filtrare i dati per gennaio\n",
    "january_df = joined_df.filter((year(col(\"Date\")) == 2017) & (month(col(\"Date\")) == 1))\n",
    "\n",
    "# Creazione colonne per i conteggi dei sentimenti\n",
    "january_df = january_df.withColumn(\"Positive_Count\", when(january_df[\"sentiment\"] == \"Positive\", 1).otherwise(0))\n",
    "january_df = january_df.withColumn(\"Negative_Count\", when(january_df[\"sentiment\"] == \"Negative\", 1).otherwise(0))\n",
    "january_df = january_df.withColumn(\"Neutral_Count\", when(january_df[\"sentiment\"] == \"Neutral\", 1).otherwise(0))\n",
    "\n",
    "# Raggruppare per giorno e calcolare la somma dei conteggi dei sentimenti\n",
    "sentiment_counts = january_df.groupBy(\"Date\").sum(\"Positive_Count\", \"Negative_Count\", \"Neutral_Count\")\n",
    "\n",
    "# Calcolo media dei conteggi per ogni sentimento\n",
    "sentiment_averages = sentiment_counts.withColumn(\"Avg_Positive\", col(\"sum(Positive_Count)\") / 31)\n",
    "sentiment_averages = sentiment_averages.withColumn(\"Avg_Negative\", col(\"sum(Negative_Count)\") / 31)\n",
    "sentiment_averages = sentiment_averages.withColumn(\"Avg_Neutral\", col(\"sum(Neutral_Count)\") / 31)\n",
    "\n",
    "# Mostrare il DataFrame risultante\n",
    "sentiment_averages.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dc5eca81-4555-4156-a5b3-6d03f26a743b",
     "showTitle": false,
     "title": ""
    },
    "id": "Utcwv8-N3GDm"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "january_sentiment_averages = sentiment_averages.filter(sentiment_averages[\"Date\"].startswith(\"2017-01\")) \\\n",
    "                                                .orderBy(\"Date\")\n",
    "dates = [str(row[\"Date\"]).split(\"-\")[-1] for row in january_sentiment_averages.collect()]\n",
    "positive_avg = [row[\"Avg_Positive\"] for row in january_sentiment_averages.collect()]\n",
    "negative_avg = [row[\"Avg_Negative\"] for row in january_sentiment_averages.collect()]\n",
    "neutral_avg = [row[\"Avg_Neutral\"] for row in january_sentiment_averages.collect()]\n",
    "\n",
    "january_bitcoin_df = bitcoin_df.filter(bitcoin_df[\"Date\"].startswith(\"2017-01\")) \\\n",
    "                               .orderBy(\"Date\")\n",
    "bitcoin_dates = [str(row[\"Date\"]).split(\"-\")[-1] for row in january_bitcoin_df.select(\"Date\").collect()]\n",
    "bitcoin_variation = [float(row[\"Variazione\"].replace(\",\", \".\")) for row in january_bitcoin_df.select(\"Variazione\").collect()]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(dates, positive_avg, label='Positive Sentiment', marker='o')\n",
    "plt.plot(dates, negative_avg, label='Negative Sentiment', marker='o')\n",
    "plt.plot(dates, neutral_avg, label='Neutral Sentiment', marker='o')\n",
    "plt.plot(bitcoin_dates, bitcoin_variation, label='Bitcoin Variation', marker='o')\n",
    "plt.xlabel('Day of January 2017')\n",
    "plt.ylabel('Average Sentiment / Bitcoin Variation')\n",
    "plt.title('Average Sentiment and Bitcoin Variation in January 2017')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Sentiment_and_Bitcoin",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
